# Problem Statement

Object Counting, Handwriting Recognition, & Anomaly Detection in Acumen Chip Images

# Description

Each image represents a counting paper with a number of acumen chips on them. Using Computer Vision techniques, teams are expected to produce model(s) which perform the following:

1. Identify the number of chips present on each counting paper.
2. Identify the handwritten manual count present on each counting paper.
3. Indicate the location of anomalies with bounding boxes.

More details can be found on the [Kaggle Competition webpage](https://www.kaggle.com/c/nus-sds-dsc2021).

# Approach

For this challenge, we used [Mask R-CNN model](https://github.com/matterport/Mask_RCNN) for Object Detection tasks. We made use of the coordinates of the ROIs generated by its Region Proposal Network.

We used VGG Annotator 2.0 for labelling. The labels are encoded as follows:

- `normal`: 1, `double_stack`: 2, `black_spot`: 3, `handwriting`: 4

## Task 1: Identify the number of chips present on each counting paper

With the information from the bounding boxes, we count the number of normal (class_id = 1) + 2 \* double_stack (class_id = 2).

## Task 2: Identify the handwritten manual count present on each counting paper

We extract the ROI of the handwriting bounding boxes (if any), and then pass the sliced image for detection using `easy-ocr` function.

- If no handwriting region is detected, the count is -1.
- If more than 1 handwriting region is detected, the bounding box with the highest confidence score will be used.
  - If the returned value cannot be recognized as valid numerals, we will use the count from Task 1 as the answer.

## Task 3: Indicate the location of anomalies with bounding boxes

As the train set only contains very few `double_stack` and `black_spot` anomalies, we generated more images for each category for labelling.

- For `double_stack`, we simply sampled and cropped the normal chips from several images and overlaid them directly on another chip on Illustrator.
- For `black_spot` anomaly, we cropped out them out and used ImageDataGenerator to augment data in different sizes, orientation, brightness, etc, and then used Illustrator to superimpose them on selected images.
  - During the process, we also rotated the chip in 180 degrees as we knew that the black spot must be either at the top left hand corner or the bottom right hand corner.

During inference, we extract the ROI, coordinates and confidence scores of the anomalies bounding boxes (if any).

# Installation

1. Clone this repository.
   ```
   git clone https://github.com/derong97/acumen-chip-cv.git
   ```
2. Download pre-trained COCO weights (mask_rcnn_coco.h5) from the [releases page](https://github.com/matterport/Mask_RCNN/releases), or our pre-trained weights (mask_rcnn_acumen_final.h5) from [Google Cloud Storage Bucket](https://storage.googleapis.com/dsc_2021/mask_rcnn_acumen_final.h5).
3. Upload this folder to Google Drive. This is because we will be using Google Colaboratory and its GPU resources for training purposes.

# Train the model

Edit `train.ipynb` accordingly.

1. Change the path to your root directory.
   ```
   os.chdir('drive/My Drive/path/to/root/dir')
   ```
2. Change the paths to your own dataset, weights, and logs directory.
   ```
   python3 acumen_config.py train --dataset=/path/to/acumen/dataset --weights=/path/to/pretrained/weights --logs=/path/to/logs
   ```

Once done, run all the cells to start the training process :) Make sure to change Runtime type to GPU.

When model training is completed, the weights can be found in the timestamp folder of your specified log directory.
Tip: monitor the `val_loss` during training, and use the weights that gives the lowest loss for inference.

# Infererence

Edit `inference.ipynb` accordingly.

1. Change the path to your root directory.
   ```
   os.chdir('drive/My Drive/path/to/root/dir')
   ```
2. Change the path to your trained weights.
   ```
   ACUMEN_WEIGHTS_PATH = ROOT_DIR + '/path/to/pretrained/weights'
   ```

Once done, run all the cells to start the inference process :)

The results can be found in `submissions.csv`.
